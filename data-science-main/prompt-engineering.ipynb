{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e83de6b-f9ce-4fc9-ba6e-009009db785b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The jupyter_ai_magics extension is already loaded. To reload it, use:\n",
      "  %reload_ext jupyter_ai_magics\n"
     ]
    }
   ],
   "source": [
    "# !pip install openai jupyter_ai\n",
    "# echo \"OPENAI_API_KEY=your-api-key\" > .env\n",
    "# %env OPENAI_API_KEY = {YOUR_API_KEY}\n",
    "\n",
    "import os\n",
    "import openai\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) \n",
    "openai.api_key = os.environ['OPENAI_API_KEY']\n",
    "openai.api_key\n",
    "\n",
    "%load_ext jupyter_ai_magics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2bfaeabf-1aea-43d4-8aeb-4a036d07815f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You act as Professional Data Scientist, Principal Solution Architect, Python / R / SAS expert with master's or PhD degrees from the world's top 1% universities; embody the role of the most qualified subject matter experts in the areas of Data Science, Analytics, Machine Learning, AI, DevSecOps, Terraform, and Amazon Web Services (AWS) Cloud; you are tasked with: in-depth analysis of large datasets to extract insights and predictions. Utilize tools such as Python, R, SQL, Pandas, NumPy, Scikit-learn, TensorFlow for this purpose. The findings should be presented in a detailed report with data visualizations and actionable recommendations. For instance, as seen in industry-leading research papers.\n"
     ]
    }
   ],
   "source": [
    "def generate_magic_prompt(task: str, tools: str, output_format: str, example: str) -> str:\n",
    "    \"\"\"\n",
    "    Generates a custom MAGIC PROMPT for a professional data scientist role.\n",
    "\n",
    "    Args:\n",
    "    - task (str): The specific data science task to be performed.\n",
    "    - tools (str): The tools and technologies to be used for the task.\n",
    "    - output_format (str): The desired format for presenting the findings.\n",
    "    - example (str): An example to illustrate the type of work expected.\n",
    "\n",
    "    Returns:\n",
    "    - str: A custom MAGIC PROMPT tailored for a professional data scientist.\n",
    "    \"\"\"\n",
    "    return (\n",
    "        \"You act as Professional Data Scientist, Principal Solution Architect, Python / R / SAS expert with master's or PhD degrees from the world's top 1% universities; embody the role of the most qualified subject matter experts in the areas of Data Science, Analytics, Machine Learning, AI, DevSecOps, Terraform, and Amazon Web Services (AWS) Cloud; \"\n",
    "        \"you are tasked with: {task}. \"\n",
    "        \"Utilize tools such as {tools} for this purpose. \"\n",
    "        \"The findings should be presented in {output_format}. \"\n",
    "        \"For instance, {example}.\"\n",
    "    ).format(task=task, tools=tools, output_format=output_format, example=example)\n",
    "\n",
    "## Magic-Prompt Usage 1\n",
    "magic_prompt = generate_magic_prompt(\n",
    "    task=\"in-depth analysis of large datasets to extract insights and predictions\",\n",
    "    tools=\"Python, R, SQL, Pandas, NumPy, Scikit-learn, TensorFlow\",\n",
    "    output_format=\"a detailed report with data visualizations and actionable recommendations\",\n",
    "    example=\"as seen in industry-leading research papers\"\n",
    ")\n",
    "\n",
    "print(magic_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2108aa37-55ff-45e4-b760-c461715e80a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ai chatgpt\n",
    "\n",
    "You act as Professional Data Scientist, Principal Solution Architect, Python / R / SAS expert with master's or PhD degrees from the world's top 1% universities; embody the role of the most qualified subject matter experts in the areas of Data Science, Analytics, Machine Learning, AI, DevSecOps, Terraform, and Amazon Web Services (AWS) Cloud; \n",
    "Explain in detail step by step the STEM Research Project at master or PhD level a top-tier university"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57b560f-3730-4ed2-ac10-8bbce07e9d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ai chatgpt\n",
    "\n",
    "You act as Professional Data Scientist, Principal Solution Architect, Python / R / SAS expert with master's or PhD degrees from the world's top 1% universities; embody the role of the most qualified subject matter experts in the areas of Data Science, Analytics, Machine Learning, AI, DevSecOps, Terraform, and Amazon Web Services (AWS) Cloud; \n",
    "Explain in detail step by step the CRISP-DM methodology from https://www.datascience-pm.com/crisp-dm-2/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4f2f23-1ec1-401c-92f6-d0edf983b24c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c31290f-7d3a-4030-8520-a8673d092547",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Magic-Prompt for a real-life end-to-end data science project following CRISP-DM Methodology\n",
    "magic_prompt = generate_magic_prompt(\n",
    "    task=\"in-depth analysis of large datasets to extract insights and predictions\",\n",
    "    tools=\"Python, R, SQL, Pandas, NumPy, Scikit-learn, TensorFlow\",\n",
    "    output_format=\"a detailed report with data visualizations and actionable recommendations\",\n",
    "    example=\"as seen in industry-leading research papers\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5c68915-7dbe-4e6e-980e-47cf832dcf49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You act as a Professional Data Scientist with master's or PhD degrees from the world's top 1% universities. Embody the role of the most qualified expert in Data Science, Analytics, Machine Learning, AI, DevSecOps, Terraform, and Amazon Web Services (AWS) Cloud. Approach this project following the CRISP-DM Methodology:\n",
      "\n",
      "### 1. Business Understanding\n",
      "Understand the project objectives and requirements from a business perspective. Define the problem statement, goals, and success criteria. Identify stakeholders and their requirements.\n",
      "\n",
      "Expected Output:\n",
      "- Documented understanding of the business problem and objectives.\n",
      "- Identified stakeholders and their requirements.\n",
      "- Defined project scope and success criteria.\n",
      "\n",
      "### 2. Data Understanding\n",
      "Focus on collecting and understanding the available data. Perform initial data exploration to identify quality, relevance, and limitations.\n",
      "\n",
      "Expected Output:\n",
      "- Identified data sources.\n",
      "- Documentation of data quality, completeness, and limitations.\n",
      "- Initial data exploration and insights.\n",
      "\n",
      "### 3. Data Preparation\n",
      "Clean, transform, and format the data for analysis. Handle missing values, outliers, and perform feature scaling. Apply data preprocessing techniques.\n",
      "\n",
      "Expected Output:\n",
      "- Cleaned and preprocessed data.\n",
      "- Feature engineering outcomes.\n",
      "- Selected features and transformed data ready for modeling.\n",
      "\n",
      "### 4. Modeling\n",
      "Apply various modeling techniques to develop suitable models. Select algorithms based on objectives and data characteristics. Train and evaluate the models using appropriate metrics.\n",
      "\n",
      "Expected Output:\n",
      "- Trained models (potentially multiple).\n",
      "- Model evaluation results based on metrics.\n",
      "- Identified best-performing model.\n",
      "\n",
      "### 5. Evaluation\n",
      "Assess the model's performance and alignment with business objectives. Use validation datasets or cross-validation techniques for thorough evaluation.\n",
      "\n",
      "Expected Output:\n",
      "- Evaluation metrics and results.\n",
      "- Determination of model's suitability for deployment.\n",
      "\n",
      "### 6. Deployment\n",
      "Deploy the chosen model into a production environment. Integrate the model into existing systems or processes and develop necessary user interfaces or APIs.\n",
      "\n",
      "Expected Output:\n",
      "- Deployed model ready for production use.\n",
      "- Documentation and training materials.\n",
      "- Integration with existing systems.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def generate_magic_prompt(crisp_dm_steps: dict) -> str:\n",
    "    \"\"\"\n",
    "    Generates a custom MAGIC PROMPT for a professional data scientist role,\n",
    "    guiding the AI to approach a data science project following the CRISP-DM Methodology.\n",
    "\n",
    "    Args:\n",
    "    - crisp_dm_steps (dict): A dictionary where keys are CRISP-DM steps and values are dictionaries \n",
    "                             containing descriptions and expected outputs for each step.\n",
    "\n",
    "    Returns:\n",
    "    - str: A custom MAGIC PROMPT tailored for a professional data scientist following CRISP-DM Methodology.\n",
    "    \"\"\"\n",
    "    prompt = (\n",
    "        \"You act as a Professional Data Scientist with master's or PhD degrees from the world's top 1% universities. \"\n",
    "        \"Embody the role of the most qualified expert in Data Science, Analytics, Machine Learning, AI, DevSecOps, Terraform, \"\n",
    "        \"and Amazon Web Services (AWS) Cloud. Approach this project following the CRISP-DM Methodology:\\n\\n\"\n",
    "    )\n",
    "\n",
    "    for step, details in crisp_dm_steps.items():\n",
    "        prompt += f\"### {step}\\n\"\n",
    "        prompt += f\"{details['description']}\\n\\n\"\n",
    "        prompt += \"Expected Output:\\n\"\n",
    "        for output in details['outputs']:\n",
    "            prompt += f\"- {output}\\n\"\n",
    "        prompt += \"\\n\"\n",
    "\n",
    "    return prompt\n",
    "\n",
    "# Example usage\n",
    "crisp_dm_steps = {\n",
    "    \"1. Business Understanding\": {\n",
    "        \"description\": (\n",
    "            \"Understand the project objectives and requirements from a business perspective. Define the problem statement, goals, \"\n",
    "            \"and success criteria. Identify stakeholders and their requirements.\"\n",
    "        ),\n",
    "        \"outputs\": [\n",
    "            \"Documented understanding of the business problem and objectives.\",\n",
    "            \"Identified stakeholders and their requirements.\",\n",
    "            \"Defined project scope and success criteria.\"\n",
    "        ],\n",
    "    },\n",
    "    \"2. Data Understanding\": {\n",
    "        \"description\": (\n",
    "            \"Focus on collecting and understanding the available data. Perform initial data exploration to identify \"\n",
    "            \"quality, relevance, and limitations.\"\n",
    "        ),\n",
    "        \"outputs\": [\n",
    "            \"Identified data sources.\",\n",
    "            \"Documentation of data quality, completeness, and limitations.\",\n",
    "            \"Initial data exploration and insights.\"\n",
    "        ],\n",
    "    },\n",
    "    \"3. Data Preparation\": {\n",
    "        \"description\": (\n",
    "            \"Clean, transform, and format the data for analysis. Handle missing values, outliers, and perform feature scaling. \"\n",
    "            \"Apply data preprocessing techniques.\"\n",
    "        ),\n",
    "        \"outputs\": [\n",
    "            \"Cleaned and preprocessed data.\",\n",
    "            \"Feature engineering outcomes.\",\n",
    "            \"Selected features and transformed data ready for modeling.\"\n",
    "        ],\n",
    "    },\n",
    "    \"4. Modeling\": {\n",
    "        \"description\": (\n",
    "            \"Apply various modeling techniques to develop suitable models. Select algorithms based on objectives and data characteristics. \"\n",
    "            \"Train and evaluate the models using appropriate metrics.\"\n",
    "        ),\n",
    "        \"outputs\": [\n",
    "            \"Trained models (potentially multiple).\",\n",
    "            \"Model evaluation results based on metrics.\",\n",
    "            \"Identified best-performing model.\"\n",
    "        ],\n",
    "    },\n",
    "    \"5. Evaluation\": {\n",
    "        \"description\": (\n",
    "            \"Assess the model's performance and alignment with business objectives. Use validation datasets or cross-validation techniques \"\n",
    "            \"for thorough evaluation.\"\n",
    "        ),\n",
    "        \"outputs\": [\n",
    "            \"Evaluation metrics and results.\",\n",
    "            \"Determination of model's suitability for deployment.\"\n",
    "        ],\n",
    "    },\n",
    "    \"6. Deployment\": {\n",
    "        \"description\": (\n",
    "            \"Deploy the chosen model into a production environment. Integrate the model into existing systems or processes and develop necessary \"\n",
    "            \"user interfaces or APIs.\"\n",
    "        ),\n",
    "        \"outputs\": [\n",
    "            \"Deployed model ready for production use.\",\n",
    "            \"Documentation and training materials.\",\n",
    "            \"Integration with existing systems.\"\n",
    "        ],\n",
    "    }\n",
    "}\n",
    "\n",
    "magic_prompt = generate_magic_prompt(crisp_dm_steps)\n",
    "print(magic_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "06d1e048-1284-49ec-9812-9500bf658b0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You act as a researcher conducting a STEM project at a top-tier university, consider the following guidelines:\n",
      "\n",
      "### Abstract\n",
      "- [Brief summary including motivation, research question, method, findings/recommendations, future vision]\n",
      "\n",
      "[Summary of motivation, research question, method, findings, future vision]\n",
      "\n",
      "### Introduction\n",
      "- [Description of the topic area, why it's interesting, and its relevance]\n",
      "\n",
      "[Context, background, importance, literature overview, problem definition, purpose, and significance]\n",
      "\n",
      "### Literature Review\n",
      "- [Summary of the literature critiqued in the proposal]\n",
      "\n",
      "[Discussion on known topic areas, research methods, challenges, critical evaluation of existing solutions, summary of problem area, gaps in literature]\n",
      "\n",
      "### Research Question(s)\n",
      "\n",
      "\n",
      "### Research Design\n",
      "\n",
      "\n",
      "### Findings, Analysis, and Discussion\n",
      "- [Division of findings, analysis, and discussion as suits the study]\n",
      "\n",
      "[Results, analysis, how findings support or contradict previous research, diagrams/tables for visual aid]\n",
      "\n",
      "### Conclusion, Limitations & Future Work\n",
      "- [Summary of contributions, identification of limitations, areas of uncertainty, and future research design plans]\n",
      "\n",
      "[Study summary, identification of limitations, areas of uncertainty, recommendations for future research]\n",
      "\n",
      "### STEM Research Methods\n",
      "[Aim and process of research, involvement of supervisor, emphasis on primary data, relevance to a group of people, contribution to knowledge]\n",
      "\n",
      "### Rubric for Marking\n",
      "[Marking criteria, areas of emphasis, expectation for quality over quantity, report structure and content requirements]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def read_markdown_file(file_path: str) -> str:\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        return file.read()\n",
    "\n",
    "def extract_section_content(content: str, section_title: str) -> str:\n",
    "    pattern = rf\"## {re.escape(section_title)}\\n(.*?)(?=\\n## |\\Z)\"\n",
    "    match = re.search(pattern, content, re.DOTALL)\n",
    "    return match.group(1).strip() if match else \"\"\n",
    "\n",
    "def generate_magic_prompt_from_md(content: str) -> str:\n",
    "    sections = [\"Abstract\", \"Introduction\", \"Literature Review\", \"Research Questions and Scoping\", \n",
    "                \"Research Design/Methods\", \"Application of Research Method\", \"Findings, Analysis, and Discussion\", \n",
    "                \"Conclusion, Limitations & Future Work\", \"STEM Research Methods\", \n",
    "                \"Rubric for Marking\"]\n",
    "\n",
    "    prompt = \"You act as a Professional Data Scientist, Cloud Solutions Architect, and Researcher with Master's or PhD degrees from the world's top 1% universities; conducting a STEM project at a top-tier university, consider the following guidelines:\\n\\n\"\n",
    "    for section in sections:\n",
    "        section_content = extract_section_content(content, section)\n",
    "        prompt += f\"### {section}\\n{section_content}\\n\\n\"\n",
    "\n",
    "    return prompt\n",
    "\n",
    "\n",
    "# Example usage\n",
    "md_content = read_markdown_file('STEM_Research_Project.md')\n",
    "magic_prompt = generate_magic_prompt_from_md(md_content)\n",
    "print(magic_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c3e464af-965b-4457-9e11-230cb7fce5f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You act as a Professional Data Scientist, Cloud Solutions Architect, and Researcher with Master's or PhD degrees from the world's top 1% universities; conducting a STEM Research Project described in STAT995 at a top-tier university, consider the following WORKFLOW:\n",
      "\n",
      "[Prompt][Task]1. Abstract\n",
      "- Condense your research into a concise abstract. What motivated this study, what were your methods, and what have you discovered?\n",
      "- Consideration: Ensure it's within 150 words, capturing the essence of your research, including Summary of motivation, research question, method, findings / recommendations, future vision.\n",
      " Next task.[/Task] \n",
      "\n",
      "[Prompt][Task]2. Introduction\n",
      "- Develop an introduction that sets the stage for your research. Why is this topic significant, and what gap does it address?\n",
      "- Consideration: Highlight the relevance to the field of Analytics as per STAT995, including Context, background, importance, literature overview, problem definition, purpose, and significance.\n",
      " Next task.[/Task] \n",
      "\n",
      "[Prompt][Task]3. Literature Review\n",
      "- Perform an in-depth literature review. How does your research align or diverge from existing knowledge?\n",
      "- Consideration: Focus on critical evaluation and synthesis of the literature, including Discussion on known topic areas, research methods, challenges, critical evaluation of existing solutions, summary of problem area, gaps in literature.\n",
      " Next task.[/Task] \n",
      "\n",
      "[Prompt][Task]4. Research Design\n",
      "- Describe your research design and methods. What approaches did you take, and how were they implemented?\n",
      "- Consideration: Include how the design aligns with STEM methodologies.\n",
      " Next task.[/Task] \n",
      "\n",
      "[Prompt][Task]5. Findings and Analysis\n",
      "- Present your findings and analysis. What data did you gather, and what does it tell us?\n",
      "- Consideration: Use diagrams or tables for clarity, linking back to your hypotheses; including Results, analysis, how findings support or contradict previous research, diagrams/tables for visual aid.\n",
      " Next task.[/Task] \n",
      "\n",
      "[Prompt][Task]6. Conclusion\n",
      "- Summarize your research findings and their implications. What contributions have you made?\n",
      "- Consideration: Discuss any limitations and potential areas for future research; including Study summary, identification of limitations, areas of uncertainty, recommendations for future research.\n",
      " Next task.[/Task] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def read_data(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        return json.load(file)\n",
    "\n",
    "def generate_prompts(data):\n",
    "    prompts = []  # Initialize prompts list here\n",
    "    for task, info in data.items():\n",
    "        prompt = f\"{task}\\n- {info['description']}\\n- Consideration: {info['consideration']}\\n\"\n",
    "        prompts.append(prompt)\n",
    "    return prompts\n",
    "\n",
    "## Load the data and generate prompts\n",
    "file_path = 'thesis_research_structure.json'  ## Contains structured research project details\n",
    "data = read_data(file_path)\n",
    "prompts = generate_prompts(data)\n",
    "\n",
    "role = \"You act as a Professional Data Scientist, Cloud Solutions Architect, and Researcher with Master's or PhD degrees from the world's top 1% universities; conducting a STEM Research Project described in STAT995 at a top-tier university, consider the following WORKFLOW:\\n\"\n",
    "print(f\"{role}\")\n",
    "\n",
    "## Print the generated prompts\n",
    "for i, prompt in enumerate(prompts, 1):\n",
    "    print(f\"[Prompt][Task]{i}. {prompt} Next task.[/Task] \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de26d6b3-ad52-4633-926a-97ee20473260",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
